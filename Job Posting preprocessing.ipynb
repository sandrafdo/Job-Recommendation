{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "from scipy import spatial\n",
    "import spacy\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import time\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1,arr2):\n",
    "    ans=1- spatial.distance.cosine(arr1,arr2)\n",
    "    if(np.isnan(ans)):\n",
    "        return 0\n",
    "    else:\n",
    "        return ans\n",
    "    \n",
    "class job_postings:    \n",
    "    def __init__(self,link):\n",
    "        self.df2=pd.read_csv(link,encoding='cp850',engine='python')\n",
    "        self.training_range=int(len(self.df2.loc[:,'uniq_id']))\n",
    "    def check_threshold(self,threshold,ele):\n",
    "        if(ele[0]!=threshold[0][0] and abs(ele[1]-threshold[0][1])<0.03):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def categorize_jobs(self):\n",
    "        #Predefined categories\n",
    "        #Compare similarities of word embeddings\n",
    "        nlp=spacy.load('en_core_web_sm')\n",
    "        job_id=self.df2.loc[:,'uniq_id'].tolist()[:self.training_range]\n",
    "        job_titles=self.df2.loc[:,'jobtitle'].tolist()[:self.training_range]\n",
    "        job_descriptions=self.df2.loc[:,'jobdescription'].tolist()[:self.training_range]\n",
    "        final_cat=pd.DataFrame(index=job_id)\n",
    "        #categories=['Network Engineer','Application Development','Big Data','Data Analyst','Software Developer','DevOps','Software Testing','Front End','Back End','Full Stack','Web Development','Information Security','Mobile developer','System Administrator','Business Analyst','Manager','Cloud']\n",
    "        categories=['Network Engineer','Full stack','QA/Test Developer','Enterprise application','DevOps','Mobile Developer','Back End','Database Administrator(DBA)','Front End','Game developer','System Administrator','Data Scientist','Business analyst','Sales professional','Product Manager','Information Security','Software Developer/Java Developer','Web Developer','Cloud Computing']\n",
    "        for category in categories:\n",
    "            final_cat[category]=np.nan\n",
    "            \n",
    "        for job_t_d in list(zip(job_id,job_titles,job_descriptions)):\n",
    "            id_job=job_t_d[0]\n",
    "            job_i=str(job_t_d[1])\n",
    "            job_d=str(job_t_d[2])\n",
    "            job_title=nlp(job_i.lower())\n",
    "            job_description=nlp(job_d.lower())\n",
    "            match_cat_title=dict()\n",
    "            match_cat_description=dict()\n",
    "            for category in categories:\n",
    "                word=nlp(category.lower())\n",
    "                match_cat_title[category]=job_title.similarity(word)\n",
    "                match_cat_description[category]=job_description.similarity(word)\n",
    "            match_cat_title=sorted(match_cat_title.items(),key=lambda x:x[1],reverse=True)\n",
    "            match_cat_description=sorted(match_cat_description.items(),key=lambda x:x[1],reverse=True)\n",
    "\n",
    "            #a represents max\n",
    "            a = match_cat_title[0]\n",
    "            cat_description= lambda x: self.check_threshold(match_cat_title,x)\n",
    "            match_cat_description=list(filter(cat_description,match_cat_description))\n",
    "            l=len(match_cat_description)\n",
    "            if(l!=0):\n",
    "                #b=match_cat_description[0]\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "                match_cat_description.extend([(match_cat_title[0][0],1)])\n",
    "                sum_proportion=sum([x[1] for x in match_cat_description])\n",
    "                for ele in match_cat_description:\n",
    "                    final_cat.loc[id_job,ele[0]]=ele[1]/sum_proportion\n",
    "            else:\n",
    "                #print(id_job)\n",
    "                final_cat.loc[id_job,a[0]]=1\n",
    "        return final_cat\n",
    "\n",
    "    def clean_skills(self):\n",
    "        extracted_skills=dict()\n",
    "        job_skills=np.asarray(self.df2.loc[:,\"skills\"])\n",
    "        for i in range(self.training_range):\n",
    "            #print(i)\n",
    "            #Method 1: Manual pre-processing\n",
    "            job_id=self.df2.iloc[i,-1]\n",
    "            #Method 2:Using NLTK\n",
    "            tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "            #print(job_skills[i])\n",
    "            if(pd.isnull(job_skills[i])):\n",
    "                continue\n",
    "            stopwords_list=stopwords.words(\"english\")\n",
    "            tokens=re.split(\"|\".join([\",\",\" and\",\"/\",\" AND\",\" or\",\" OR\",\";\"]),job_skills[i])\n",
    "            tokens=list(set(tokens))\n",
    "            extracted_skills[job_id]=[]\n",
    "            extracted_skills[job_id].extend(tokens)\n",
    "        return extracted_skills\n",
    "    \n",
    "    def extract_skills(self,extracted_skills):\n",
    "        nlp=spacy.load('en_core_web_sm')\n",
    "        df_languages=pd.read_csv(\"Documents/data/languages.csv\")\n",
    "        df_frameworks=pd.read_csv(\"Documents/data/frameworks.csv\")\n",
    "        df_database=pd.read_csv(\"Documents/data/database.csv\")\n",
    "        df_os=pd.read_csv(\"Documents/data/operating_systems.csv\")\n",
    "        df_plat=pd.read_csv(\"Documents/data/platforms.csv\")\n",
    "        frameworks=str(df_frameworks.iloc[:,1].tolist())\n",
    "        frameworks=[x.lower().strip() for x in frameworks]\n",
    "        #frameworks=[str(x).split(\",\")[0] for x in df_frameworks.iloc[:,1]]\n",
    "        languages=str(df_languages.iloc[:,0].tolist())\n",
    "        languages=[x.lower().strip() for x in languages]\n",
    "        #frameworks=[x.lower().strip().split('\\t')[0] for x in frameworks]\n",
    "        databases=str(df_database.iloc[:,0].tolist())\n",
    "        databases=[x.lower().strip() for x in databases]\n",
    "        op_systems=str(df_os.iloc[:,0].tolist())\n",
    "        op_systems=[x.lower().strip() for x in op_systems]\n",
    "        platforms=str(df_plat.iloc[:,1].tolist())\n",
    "        #print(platforms)\n",
    "        platforms=[x.lower().strip() for x in platforms]\n",
    "        #print(frameworks)\n",
    "        new_extracted=dict()\n",
    "        for ele in extracted_skills.keys():\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            final_os=''\n",
    "            #print(extracted_skills[ele])\n",
    "            for skill in extracted_skills[ele]:\n",
    "                skill_base=skill.lower().strip()\n",
    "                #print(skill_base)\n",
    "                if(skill_base in languages):\n",
    "                    if(final_lang==''):\n",
    "                        final_lang=skill_base\n",
    "                    else:\n",
    "                        final_lang=final_lang+\",\"+skill_base\n",
    "                elif(skill_base in frameworks):\n",
    "                    if(final_frame==''):\n",
    "                        final_frame=skill_base\n",
    "                    else:\n",
    "                        final_frame=final_frame+\",\"+skill_base\n",
    "                elif(skill_base in databases):\n",
    "                    if(final_database==''):\n",
    "                        final_database=skill_base\n",
    "                    else:\n",
    "                        final_database=final_database+\",\"+skill_base\n",
    "                elif(skill_base in op_systems):\n",
    "                    if(final_os==''):\n",
    "                        final_os=skill_base\n",
    "                    else:\n",
    "                        final_os=final_os+\",\"+skill_base\n",
    "                elif(skill_base in platforms):\n",
    "                    if(final_plat==''):\n",
    "                        final_plat=skill_base\n",
    "                    else:\n",
    "                        final_plat=final_plat+\",\"+skill_base\n",
    "                else:\n",
    "                    if(final_others==''):\n",
    "                        final_others=skill_base\n",
    "                    else:\n",
    "                        final_others=final_others+\",\"+skill_base\n",
    "            new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        #print((list(new_extracted.items()))[:100])\n",
    "        for ele,describe in list(zip(self.df2.loc[:,'uniq_id'],self.df2.loc[:,'jobdescription'].tolist()))[:self.training_range]:\n",
    "            doc=nlp(describe)\n",
    "            final_lang=''\n",
    "            final_frame=''\n",
    "            final_others=''\n",
    "            final_database=''\n",
    "            final_plat=''\n",
    "            final_os=''\n",
    "            for ent in doc.ents:\n",
    "                word=ent.text\n",
    "                word=word.lower().strip()\n",
    "                try:\n",
    "                    if(word in languages and word not in final_lang and word not in new_extracted[ele][0].split(\",\")):\n",
    "                        if(final_lang==''):\n",
    "                            final_lang=word\n",
    "                        else:\n",
    "                            final_lang=final_lang+\",\"+word\n",
    "                    elif(word in frameworks and word not in final_frame and word not in new_extracted[ele][1].split(\",\")):\n",
    "                        if(final_frame==''):\n",
    "                            final_frame=word\n",
    "                        else:\n",
    "                            final_frame=final_frame+\",\"+word\n",
    "                    elif(word in databases and word not in final_database and word not in new_extracted[ele][2].split(\",\")):\n",
    "                        if(final_database==''):\n",
    "                            final_database=word\n",
    "                        else:\n",
    "                            final_database=final_database+\",\"+word\n",
    "                    elif(word in op_systems and word not in final_os and word not in new_extracted[ele][3].split(\",\")):\n",
    "                        if(final_os==''):\n",
    "                            final_os=word\n",
    "                        else:\n",
    "                            final_os=final_os+\",\"+word\n",
    "                    elif(word in platforms and word not in final_plat and word not in new_extracted[ele][4].split(\",\")):\n",
    "                        if(final_plat==''):\n",
    "                            final_plat=word\n",
    "                        else:\n",
    "                            final_plat=final_plat+\",\"+word\n",
    "                    else:\n",
    "                        if(final_others==''):\n",
    "                            final_others=word\n",
    "                        else:\n",
    "                            final_others=final_others+\",\"+word\n",
    "                except KeyError:\n",
    "                    print(\"\")\n",
    "            try:\n",
    "                if(final_lang!=''):\n",
    "                    new_extracted[ele][0]+=\",\"+final_lang\n",
    "                if(final_frame!=''):\n",
    "                    new_extracted[ele][1]+=\",\"+final_frame\n",
    "                if(final_database!=''):\n",
    "                    new_extracted[ele][2]+=\",\"+final_database\n",
    "                if(final_os!=''):\n",
    "                    new_extracted[ele][3]+=\",\"+final_os\n",
    "                if(final_plat!=''):\n",
    "                    new_extracted[ele][4]+=\",\"+final_plat\n",
    "                if(final_others!=''):\n",
    "                    new_extracted[ele][5]+=\",\"+final_others\n",
    "            except KeyError:\n",
    "                print(\"\")\n",
    "            new_extracted[ele]=[final_lang,final_frame,final_database,final_os,final_plat,final_others]\n",
    "        extracted_skills_df=pd.DataFrame.from_dict(new_extracted,orient='index',columns=['Language','Framework','Database','OS','Platform','Others'])\n",
    "        return extracted_skills_df\n",
    "    \n",
    "    def create_job_profile(self,extracted_skills_df,domain_df):\n",
    "        job_id=extracted_skills_df.index.tolist()\n",
    "        languages_df=pd.DataFrame(index=job_id)\n",
    "        platforms_df=pd.DataFrame(index=job_id)\n",
    "        frameworks_df=pd.DataFrame(index=job_id)\n",
    "        databases_df=pd.DataFrame(index=job_id)\n",
    "        \n",
    "        for job,lang,frame,plat,datab in list(zip(job_id,extracted_skills_df.loc[:,'Language'].tolist(),extracted_skills_df.loc[:,'Framework'].tolist(),extracted_skills_df.loc[:,'Platform'].tolist(),extracted_skills_df.loc[:,'Database'].tolist())):\n",
    "            #Languages\n",
    "            l=lang.split(\",\")\n",
    "            if(lang!=np.nan or lang!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in languages_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        languages_df[ele]=np.nan\n",
    "                    languages_df.loc[job,ele]=1\n",
    "            \n",
    "            #Frameworks\n",
    "            l=frame.split(\",\")\n",
    "            if(frame!=np.nan or frame!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in frameworks_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        frameworks_df[ele]=np.nan\n",
    "                    frameworks_df.loc[job,ele]=1\n",
    "\n",
    "            #Platforms\n",
    "            l=plat.split(\",\")\n",
    "            if(plat!=np.nan or plat!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in platforms_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        platforms_df[ele]=np.nan\n",
    "                    platforms_df.loc[job,ele]=1\n",
    "            \n",
    "            #Databases\n",
    "            l=datab.split(\",\")\n",
    "            if(datab!=np.nan or datab!=''):\n",
    "                for ele in l:\n",
    "                    if(ele==''):\n",
    "                        continue\n",
    "                    if(ele not in databases_df.columns):\n",
    "                        #languages.append(ele)\n",
    "                        databases_df[ele]=np.nan\n",
    "                    databases_df.loc[job,ele]=1\n",
    "        languages_df=languages_df.reindex_axis(sorted(languages_df.columns), axis=1)\n",
    "        frameworks_df=frameworks_df.reindex_axis(sorted(frameworks_df.columns), axis=1)\n",
    "        platforms_df=platforms_df.reindex_axis(sorted(platforms_df.columns), axis=1)\n",
    "        databases_df=databases_df.reindex_axis(sorted(databases_df.columns), axis=1)\n",
    "        domain_df=domain_df.reindex_axis(sorted(domain_df.columns), axis=1)\n",
    "        \n",
    "        languages_df.index.name=frameworks_df.index.name=platforms_df.index.name=databases_df.index.name=domain_df.index.name='uniq_id'\n",
    "        languages_df.to_csv(\"Documents/data/languages_job_profile.csv\")\n",
    "        frameworks_df.to_csv(\"Documents/data/frameworks_job_profile.csv\")\n",
    "        platforms_df.to_csv(\"Documents/data/platforms_job_profile.csv\")\n",
    "        databases_df.to_csv(\"Documents/data/databases_job_profile.csv\")\n",
    "        domain_df.to_csv(\"Documents/data/domain_job_profile.csv\")\n",
    "        #print(languages_df.columns)\n",
    "        \n",
    "    def clean_common_profile(self,df_user,df_job,flag):\n",
    "        #Shift .net from languages to frameworks\n",
    "        if(flag=='Language'):\n",
    "            print(df_job.columns.tolist())\n",
    "            #bash and bash/shell\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.ix[count,'bash']=1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('bash/shell',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'bash/shell']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.ix[count,'bash']=1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('bash/shell',axis=1)\n",
    "\n",
    "        if(flag=='Framework'):\n",
    "            print(df_user.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'nodejs']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.ix[count,'node.js']=1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('nodejs',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'nodejs']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.ix[count,'node.js']=1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('nodejs',axis=1)\n",
    "            \n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'angularjs']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.ix[count,'angular']=1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('angularjs',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'angularjs']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.ix[count,'angular']=1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('angularjs',axis=1)\n",
    "            \n",
    "        if(flag=='Platform'):\n",
    "            print(df_user.columns.tolist())\n",
    "        if(flag=='Database'):\n",
    "            print(df_user.columns.tolist())\n",
    "            count=0\n",
    "            for ele in df_user.loc[:,'microsoft sql server']:\n",
    "                if(ele==1.0):\n",
    "                    df_user.ix[count,'sql server']=1.0\n",
    "                count=count+1\n",
    "            df_user=df_user.drop('microsoft sql server',axis=1)\n",
    "            count=0\n",
    "            for ele in df_job.loc[:,'microsoft sql server']:\n",
    "                if(ele==1.0):\n",
    "                    df_job.ix[count,'sql server']=1.0\n",
    "                count=count+1\n",
    "            df_job=df_job.drop('microsoft sql server',axis=1)\n",
    "        return df_user,df_job\n",
    "\n",
    "    #Input is two dataframes    \n",
    "    def create_common_profile(self,flag=0):\n",
    "        if(flag==0):\n",
    "            #Domain\n",
    "            userprofile=pd.read_csv(\"Documents/data/DevType.csv\",index_col='Respondent')\n",
    "            jobprofile=pd.read_csv(\"Documents/data/domain_job_profile.csv\",index_col=False)\n",
    "            print(jobprofile.index)\n",
    "            jobprofile.drop('uniq_id', axis=1, inplace=True)\n",
    "            jobprofile.index.name='uniq_id'\n",
    "            print(\"index 2in domain\")\n",
    "            print(jobprofile.index)\n",
    "            #print(jobprofile.loc[:,'uniq_id'])\n",
    "            userprofile.rename(columns={'Product manager':'Product Manager','Back-end developer':'Back End','C-suite executive (CEO, CTO, etc.)':'C-suite executive','Data scientist or machine learning specialist':'Data Scientist','Database administrator':'Database Administrator(DBA)','Mobile developer':'Mobile Developer','Desktop or enterprise applications developer':'Enterprise application','DevOps specialist':'DevOps','Front-end developer':'Front End','Full-stack developer':'Full stack','Marketing or sales professional':'Sales professional','QA or test developer':'QA/Test Developer','System administrator':'System Administrator','Game or graphics developer':'Game developer'},inplace=True)\n",
    "            jobprofile.rename(columns={'Business analyst':'Data or business analyst'},inplace=True)\n",
    "            print(userprofile.columns)\n",
    "            print(jobprofile.columns)\n",
    "            print(\"index in domain\")\n",
    "            print(jobprofile.index)\n",
    "            #Present in userprofile but not in jobprofile\n",
    "            a=list(set(userprofile.columns)-set(jobprofile.columns))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    jobprofile[i]=0\n",
    "            b=list(set(jobprofile.columns)-set(userprofile.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    userprofile[i]=0\n",
    "            userprofile=userprofile[sorted(userprofile.columns.tolist())]\n",
    "            jobprofile=jobprofile[sorted(jobprofile.columns.tolist())]\n",
    "            #Exclude \n",
    "            userprofile=userprofile[userprofile.columns.tolist()]\n",
    "            jobprofile=jobprofile[jobprofile.columns.tolist()]\n",
    "            userprofile.to_csv(\"Documents/data/domain_user_profile.csv\")\n",
    "            jobprofile.to_csv(\"Documents/data/domain_job_profile.csv\")\n",
    "\n",
    "            #Languages\n",
    "            df_user=pd.read_csv(\"Documents/data/LanguageWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(\"Documents/data/languages_job_profile.csv\",index_col=False)\n",
    "            df_job.index.name='uniq_id'\n",
    "            df_job.rename(columns={'visual basic .net':'vb.net'},inplace=True)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "            columns_to_add=[]\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            #print(df_job.index)        \n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "            print(\"index 2\")\n",
    "            print(df_job.index)\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Language')\n",
    "            df_user.to_csv(\"Documents/data/languages_profile_user.csv\")\n",
    "            df_job.to_csv(\"Documents/data/languages_profile_job.csv\")\n",
    "\n",
    "            #Frameworks\n",
    "            df_user=pd.read_csv(\"Documents/data/FrameworkWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(\"Documents/data/frameworks_job_profile.csv\",index_col=False) \n",
    "            df_job.index.name='uniq_id'\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0        \n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Framework')   \n",
    "            df_user.to_csv(\"Documents/data/frameworks_profile_user.csv\")\n",
    "            df_job.to_csv(\"Documents/data/frameworks_profile_job.csv\")\n",
    "\n",
    "            #Platforms\n",
    "            df_user=pd.read_csv(\"Documents/data/PlatformWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(\"Documents/data/platforms_job_profile.csv\",index_col=False) \n",
    "            print(df_user.columns)\n",
    "            df_job.index.name='uniq_id'\n",
    "            print(df_job.columns)\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "            print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Platform')        \n",
    "            df_user.to_csv(\"Documents/data/platforms_profile_user.csv\")\n",
    "            df_job.to_csv(\"Documents/data/platforms_profile_job.csv\")\n",
    "\n",
    "            #Databases\n",
    "            df_user=pd.read_csv(\"Documents/data/DatabaseWorkedWith.csv\",index_col='Respondent')\n",
    "            df_job=pd.read_csv(\"Documents/data/databases_job_profile.csv\",index_col=False) \n",
    "            df_job.index.name='uniq_id'\n",
    "            df_user.columns=list(map(lambda x:x.lower(),df_user.columns))\n",
    "            df_job.columns=list(map(lambda x:x.lower(),df_job.columns))\n",
    "\n",
    "            a=list(set(df_user.columns)-(set(df_job.columns)))\n",
    "            print(a)\n",
    "            for i in a:\n",
    "                if(i!='Respondent'):\n",
    "                    df_job[i]=0\n",
    "            b=list(set(df_job.columns)-set(df_user.columns))\n",
    "            print(b)\n",
    "            for i in b:\n",
    "                if(i!='uniq_id'):\n",
    "                    df_user[i]=0\n",
    "            df_user=df_user[sorted(df_user.columns.tolist())]\n",
    "            df_job=df_job[sorted(df_job.columns.tolist())]\n",
    "\n",
    "           # print(len(set(df_user.columns).intersection(df_job.columns)),len(df_user.columns))\n",
    "            df_user,df_job=self.clean_common_profile(df_user,df_job,'Database')        \n",
    "            df_user.to_csv(\"Documents/data/databases_profile_user.csv\")\n",
    "            df_job.to_csv(\"Documents/data/databases_profile_job.csv\")\n",
    "            \n",
    "        #flag indicates that a new user profile\n",
    "    def match_profile(self,input_path,user_id,flag=0):\n",
    "        #Match a given user_id with all jobs in the database\n",
    "        \n",
    "        #Check if user id exists\n",
    "        df=pd.read_csv(\"Documents/data/domain_user_profile.csv\",index_col='Respondent')\n",
    "        #print(df.columns)\n",
    "        matches=dict()\n",
    "        if(flag==0):\n",
    "            if(user_id in df.index):\n",
    "                userdomain=df.loc[user_id,:]\n",
    "                #print(userdomain)\n",
    "                #If it does, retrieve the user profile from input_path\n",
    "                df=pd.read_csv(\"Documents/data/languages_profile_user.csv\",index_col='Respondent')\n",
    "                userlanguages=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(\"Documents/data/frameworks_profile_user.csv\",index_col='Respondent')\n",
    "                userframeworks=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(\"Documents/data/platforms_profile_user.csv\",index_col='Respondent')\n",
    "                userplatforms=df.loc[user_id,:]\n",
    "\n",
    "                df=pd.read_csv(\"Documents/data/databases_profile_user.csv\",index_col='Respondent')\n",
    "                userdatabases=df.loc[user_id,:]\n",
    "\n",
    "                userdomain=np.asarray(userdomain.fillna(0))\n",
    "                userlanguages=np.asarray(userlanguages.fillna(0))\n",
    "                userframeworks=np.asarray(userframeworks.fillna(0))\n",
    "                userplatforms=np.asarray(userplatforms.fillna(0))\n",
    "                userdatabases=np.asarray(userdatabases.fillna(0))\n",
    "                #print(userdomain)\n",
    "            else:\n",
    "                print(\"error! user id not in Dataset\")\n",
    "            #If it doesn't,take user profile as input\n",
    "        else:\n",
    "            \n",
    "            print(\"New user!Enter details..\")\n",
    "            name=input(\"Enter full name\")\n",
    "            skills=input(\"Enter skills(comma separated). These are programming languages, frameworks,platforms or databases you have experience with\").split(\",\")\n",
    "            domains=''\n",
    "            flag=1\n",
    "            while(1):\n",
    "                print(\"Enter domain(s) of interest separated by commas(Names are case sensitive). Should be one of the following:\")\n",
    "                for i in df.columns:\n",
    "                    print(i,end=\",\")\n",
    "                domains=input().split(\",\")\n",
    "                for domain in domains:\n",
    "                    if(domain not in df.columns):\n",
    "                        flag=0\n",
    "                        break\n",
    "                if(flag==1):\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter valid domain\")\n",
    "\n",
    "            \n",
    "            \n",
    "            #domains=list(map(lambda x:x.lower(),domains))\n",
    "            skills=list(map(lambda x:x.lower(),skills))                \n",
    "\n",
    "            userdomain=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for domain in domains:\n",
    "                dictionary[domain]=1.0\n",
    "            userdomain=userdomain.append(dictionary,ignore_index=True)\n",
    "\n",
    "\n",
    "            df=pd.read_csv(\"Documents/data/languages_profile_user.csv\",index_col='Respondent')\n",
    "            userlanguages=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userlanguages=userlanguages.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(\"Documents/data/frameworks_profile_user.csv\",index_col='Respondent')\n",
    "            userframeworks=pd.DataFrame(columns=df.columns)\n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userframeworks=userframeworks.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(\"Documents/data/platforms_profile_user.csv\",index_col='Respondent')\n",
    "            userplatforms=pd.DataFrame(columns=df.columns)                \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userplatforms=userplatforms.append(dictionary,ignore_index=True)\n",
    "\n",
    "            df=pd.read_csv(\"Documents/data/databases_profile_user.csv\",index_col='Respondent')\n",
    "            userdatabases=pd.DataFrame(columns=df.columns)               \n",
    "            dictionary=dict()\n",
    "            for skill in skills:\n",
    "                if(skill in df.columns):\n",
    "                    dictionary[skill]=1.0\n",
    "            userdatabases=userdatabases.append(dictionary,ignore_index=True)\n",
    "            #print(userdomain)\n",
    "            userdomain=np.asarray(userdomain.iloc[0,:].fillna(0))\n",
    "            userlanguages=np.asarray(userlanguages.iloc[0,:].fillna(0))\n",
    "            userframeworks=np.asarray(userframeworks.iloc[0,:].fillna(0))\n",
    "            userplatforms=np.asarray(userplatforms.iloc[0,:].fillna(0))\n",
    "            userdatabases=np.asarray(userdatabases.iloc[0,:].fillna(0))\n",
    "                \n",
    "        jobdomain=pd.read_csv(\"Documents/data/domain_job_profile.csv\",index_col='uniq_id')\n",
    "        joblanguages=pd.read_csv('Documents/data/languages_profile_job.csv',index_col='uniq_id')\n",
    "        jobframeworks=pd.read_csv('Documents/data/frameworks_profile_job.csv',index_col='uniq_id')\n",
    "        jobplatforms=pd.read_csv('Documents/data/platforms_profile_job.csv',index_col='uniq_id')\n",
    "        jobdatabases=pd.read_csv('Documents/data/databases_profile_job.csv',index_col='uniq_id')\n",
    "        #print(len(jobdomain.index),len(joblanguages.index))\n",
    "        start=time.time()\n",
    "        for i in jobdomain.index:\n",
    "            #print(i)\n",
    "            domain=jobdomain.loc[i,:].fillna(0)\n",
    "            language=joblanguages.loc[i,:].fillna(0)\n",
    "            framework=jobframeworks.loc[i,:].fillna(0)\n",
    "            platform=jobplatforms.loc[i,:].fillna(0)\n",
    "            database=jobdatabases.loc[i,:].fillna(0)\n",
    "            job_id=str(i)\n",
    "            domain=np.asarray(domain)\n",
    "            language=np.asarray(language)\n",
    "            framework=np.asarray(framework)\n",
    "            platform=np.asarray(platform)\n",
    "            database=np.asarray(database)\n",
    "            t=time.time()\n",
    "            #print(len(domain),len(userdomain))\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            #print(score)\n",
    "            matches[job_id]=score\n",
    "            score=(0.7*cosine_similarity(domain,userdomain))+(0.3*(cosine_similarity(language,userlanguages)+cosine_similarity(framework,userframeworks)+cosine_similarity(platform,userplatforms)+cosine_similarity(database,userdatabases)))\n",
    "            #Initializing job profiles for later access\n",
    "            #print(score)\n",
    "            self.job_domain=domain\n",
    "            self.job_language=language\n",
    "            self.job_framework=framework\n",
    "            self.job_platform=platform\n",
    "            self.job_database=database\n",
    "            \n",
    "            self.user_domain=userdomain\n",
    "            self.user_language=userlanguages\n",
    "            self.user_framework=userframeworks\n",
    "            self.user_platform=userplatforms\n",
    "            self.user_database=userdatabases\n",
    "            \n",
    "        matches=sorted(matches.items(),key=lambda x:x[1],reverse=True)\n",
    "        recommendations=matches[:10]\n",
    "        #title=matches[0]\n",
    "        score=matches[1]\n",
    "        #print(\"Recommendations are\",'\\n')\n",
    "        #print(\"The Job ID and Score\",'\\n',recommendations,'\\n')\n",
    "        rows=pd.DataFrame(columns=self.df2.columns)\n",
    "        count=0\n",
    "        title= []\n",
    "        score= []\n",
    "        for i in recommendations:\n",
    "            title.append(i[0])\n",
    "            score.append(i[1])\n",
    "            row=self.df2[self.df2['uniq_id']==i[0]]\n",
    "            #rows[count]=np.asarray(row.values.T.tolist()[0])\n",
    "            rows=rows.append(row.iloc[:,0:9])\n",
    "            count=count+1\n",
    "            #print(row)\n",
    "        end=time.time()\n",
    "        #print(\"total time for building similarity matrix \")\n",
    "        #print(end-start)\n",
    "        acc=mean(score)\n",
    "        print(\"Similarity accuracy:\",acc)\n",
    "        #plt.plot(title,score, color='b')\n",
    "        #plt.xlabel('Title')\n",
    "        #plt.ylabel('Score')\n",
    "        #plt.title('Accuracy')\n",
    "        #plt.show()\n",
    "        return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user!Enter details..\n",
      "Enter full namejesus\n",
      "Enter skills(comma separated). These are programming languages, frameworks,platforms or databases you have experience withpython\n",
      "Enter domain(s) of interest separated by commas(Names are case sensitive). Should be one of the following:\n",
      "Back End,C-suite executive,Cloud Computing,Data Scientist,Data or business analyst,Database Administrator(DBA),Designer,DevOps,Educator or academic researcher,Embedded applications or devices developer,Engineering manager,Enterprise application,Front End,Full stack,Game developer,Information Security,Mobile Developer,Network Engineer,Product Manager,QA/Test Developer,Sales professional,Software Developer/Java Developer,Student,System Administrator,Web Developer,Full stack\n",
      "Similarity accuracy: 0.9170261355604602\n",
      "Top 10 recommendations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>employmenttype_jobstatus</th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>jobid</th>\n",
       "      <th>joblocation_address</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>postdate</th>\n",
       "      <th>skills</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>url_advertisement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>Marriott</td>\n",
       "      <td>Full Time, Permanent</td>\n",
       "      <td>My client is a world-class media and entertain...</td>\n",
       "      <td>10121728</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Full-Stack Python Developer</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Linux, Python, REST, AWS,</td>\n",
       "      <td>39d56fc47d8fec2c2baa9e6e06142181</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>Re-route Dreams Consultancy LLP</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Local NYC candidatesWe cannot sponsor visas at...</td>\n",
       "      <td>90751608</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Python, JavaScript, MYSQL</td>\n",
       "      <td>982a56232d394d4022fd854700f5b26e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>Learning Mate Solutions Private Limited</td>\n",
       "      <td>C2H W2, 6 Months</td>\n",
       "      <td>Job Description: Client is looking for a well-...</td>\n",
       "      <td>COMSYSD</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>60 minutes ago</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>b3292ac7be947e3a89b0853f4a7e2577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>BC Web Wise Pvt. Limited</td>\n",
       "      <td>Full Time, Contract Corp-To-Corp, Contract Ind...</td>\n",
       "      <td>Position  Full Stack EngineerLocation  Coimbat...</td>\n",
       "      <td>10109301</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>C#, ASP.NET, Python, AWS, Google Cloud, Azure</td>\n",
       "      <td>6611fbe1b740c2c29d4365ff9d60eefa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>Quess Corp Ltd.</td>\n",
       "      <td>Contract W2, 6+ months CTH</td>\n",
       "      <td>Exciting and challenging opportunity for a ful...</td>\n",
       "      <td>armada</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Full Stack Software Engineer</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Background/Experience requirements: * 5-10+ ye...</td>\n",
       "      <td>be66d6ebd315eaf5c98c522375c8e1e5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11702</th>\n",
       "      <td>Prince Gold and Diamonds India Pvt. Ltd.</td>\n",
       "      <td>Contract W2, 12 Months</td>\n",
       "      <td>Proficient in RESTful web servicesProficient i...</td>\n",
       "      <td>saicon</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>90d755eb5b34547c31978ce7a6eb519f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15564</th>\n",
       "      <td>EHS Engineers</td>\n",
       "      <td>C2H W2</td>\n",
       "      <td>Job Description:- Hands on Programmer with dee...</td>\n",
       "      <td>iconma</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Full-stack Developer</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Python, Open Stack, REST API</td>\n",
       "      <td>357a886cbeaac5a74c53a11665f6a45c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18091</th>\n",
       "      <td>Talent Leads Hr Solutions Pvt Ltd</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Job descriptionThe talented full stack develop...</td>\n",
       "      <td>10115962</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>OO Development</td>\n",
       "      <td>7e8bcea2f4cdc698b6d614850ca397f2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20288</th>\n",
       "      <td>Pentagon Global Solutions Limited</td>\n",
       "      <td>C2H W2, 6 months</td>\n",
       "      <td>You must:Love experimenting with the new techn...</td>\n",
       "      <td>10267832</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Full stack Developer</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Docker , Kubernetes/Swarm/Mesos microservice a...</td>\n",
       "      <td>ec92ff4d7a1a9a99e49f5792e1be2582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Technosoft Global Services Pvt Ltd</td>\n",
       "      <td>Contract Independent, 3+ mon CTH</td>\n",
       "      <td>As a Full Stack Software Engineer, you will co...</td>\n",
       "      <td>armada</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Full stack Software Engineer</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Skills and Experience required * Full-stack en...</td>\n",
       "      <td>8c87853f2cb2977e05df98497bcb7583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company  \\\n",
       "3299                                   Marriott   \n",
       "2987            Re-route Dreams Consultancy LLP   \n",
       "5531    Learning Mate Solutions Private Limited   \n",
       "5779                   BC Web Wise Pvt. Limited   \n",
       "11162                           Quess Corp Ltd.   \n",
       "11702  Prince Gold and Diamonds India Pvt. Ltd.   \n",
       "15564                             EHS Engineers   \n",
       "18091         Talent Leads Hr Solutions Pvt Ltd   \n",
       "20288         Pentagon Global Solutions Limited   \n",
       "281          Technosoft Global Services Pvt Ltd   \n",
       "\n",
       "                                employmenttype_jobstatus  \\\n",
       "3299                                Full Time, Permanent   \n",
       "2987                                           Full Time   \n",
       "5531                                    C2H W2, 6 Months   \n",
       "5779   Full Time, Contract Corp-To-Corp, Contract Ind...   \n",
       "11162                         Contract W2, 6+ months CTH   \n",
       "11702                             Contract W2, 12 Months   \n",
       "15564                                             C2H W2   \n",
       "18091                                          Full Time   \n",
       "20288                                   C2H W2, 6 months   \n",
       "281                     Contract Independent, 3+ mon CTH   \n",
       "\n",
       "                                          jobdescription     jobid  \\\n",
       "3299   My client is a world-class media and entertain...  10121728   \n",
       "2987   Local NYC candidatesWe cannot sponsor visas at...  90751608   \n",
       "5531   Job Description: Client is looking for a well-...   COMSYSD   \n",
       "5779   Position  Full Stack EngineerLocation  Coimbat...  10109301   \n",
       "11162  Exciting and challenging opportunity for a ful...    armada   \n",
       "11702  Proficient in RESTful web servicesProficient i...    saicon   \n",
       "15564  Job Description:- Hands on Programmer with dee...    iconma   \n",
       "18091  Job descriptionThe talented full stack develop...  10115962   \n",
       "20288  You must:Love experimenting with the new techn...  10267832   \n",
       "281    As a Full Stack Software Engineer, you will co...    armada   \n",
       "\n",
       "      joblocation_address                      jobtitle        postdate  \\\n",
       "3299             Banglore   Full-Stack Python Developer     3 weeks ago   \n",
       "2987             Banglore           Full Stack Engineer     2 weeks ago   \n",
       "5531           Coimbatore           Full Stack Engineer  60 minutes ago   \n",
       "5779           Coimbatore           Full Stack Engineer      3 days ago   \n",
       "11162           Hyderabad  Full Stack Software Engineer     4 hours ago   \n",
       "11702             Chennai          Full Stack Developer    10 hours ago   \n",
       "15564            Banglore          Full-stack Developer     2 weeks ago   \n",
       "18091            Banglore          Full Stack Developer      4 days ago   \n",
       "20288             Chennai          Full stack Developer      2 days ago   \n",
       "281             New Delhi  Full stack Software Engineer     5 hours ago   \n",
       "\n",
       "                                                  skills  \\\n",
       "3299                           Linux, Python, REST, AWS,   \n",
       "2987                           Python, JavaScript, MYSQL   \n",
       "5531                                 Full Stack Engineer   \n",
       "5779       C#, ASP.NET, Python, AWS, Google Cloud, Azure   \n",
       "11162  Background/Experience requirements: * 5-10+ ye...   \n",
       "11702                               Full Stack Developer   \n",
       "15564                       Python, Open Stack, REST API   \n",
       "18091                                     OO Development   \n",
       "20288  Docker , Kubernetes/Swarm/Mesos microservice a...   \n",
       "281    Skills and Experience required * Full-stack en...   \n",
       "\n",
       "                                uniq_id url_advertisement  \n",
       "3299   39d56fc47d8fec2c2baa9e6e06142181               NaN  \n",
       "2987   982a56232d394d4022fd854700f5b26e               NaN  \n",
       "5531   b3292ac7be947e3a89b0853f4a7e2577               NaN  \n",
       "5779   6611fbe1b740c2c29d4365ff9d60eefa               NaN  \n",
       "11162  be66d6ebd315eaf5c98c522375c8e1e5               NaN  \n",
       "11702  90d755eb5b34547c31978ce7a6eb519f               NaN  \n",
       "15564  357a886cbeaac5a74c53a11665f6a45c               NaN  \n",
       "18091  7e8bcea2f4cdc698b6d614850ca397f2               NaN  \n",
       "20288  ec92ff4d7a1a9a99e49f5792e1be2582               NaN  \n",
       "281    8c87853f2cb2977e05df98497bcb7583               NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=job_postings(\"Documents/data/job_sample.csv\")\n",
    "\n",
    "#Path represents the location where final job and user profiles\n",
    "df_user=pd.read_csv(\"Documents/data/survey_results_public.csv\")\n",
    "df_job=pd.read_csv(\"Documents/data/job_sample.csv\",encoding='cp850')\n",
    "\n",
    "#Pass a third parameter(flag) as 1 in order to get your recommendations!\n",
    "rows=obj.match_profile(\"Documents/data/\",3,1)\n",
    "print(\"Top 10 recommendations\")\n",
    "rows\n",
    "#with open('Documents/recommendation.csv','a', encoding='cp850') as f:   \n",
    "    #rows.to_csv(f, header=False)\n",
    "#rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
